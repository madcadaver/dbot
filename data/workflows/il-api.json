{
  "1": {
    "inputs": {
      "ckpt_name": "illustriousXLPersonalMerge_v30Noob10based.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "2": {
    "inputs": {
      "stop_at_clip_layer": -2,
      "clip": [
        "1",
        1
      ]
    },
    "class_type": "CLIPSetLastLayer",
    "_meta": {
      "title": "CLIP Set Last Layer"
    }
  },
  "3": {
    "inputs": {
      "text": [
        "21",
        0
      ],
      "clip": [
        "18",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "4": {
    "inputs": {
      "text": "embedding:lazyneg, embedding:easynegative, deformation, sketch, censor, (worst quality), (low quality), lowres, normal quality, ((monochrome)), ((grayscale)), ((watermark)), bad anatomy, bad hands, bad mouth, bad tongue, bad arms, extra arms, bad eyes, extra limbs, impregnation, dull quality, 3d model, flat colour, no shading, simple background, white background, toon, loli",
      "clip": [
        "18",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "5": {
    "inputs": {
      "seed": [
        "43",
        0
      ],
      "steps": 80,
      "cfg": 6,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 1,
      "model": [
        "18",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "latent_image": [
        "41",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "7": {
    "inputs": {
      "samples": [
        "14",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "8": {
    "inputs": {
      "filename_prefix": [
        "31",
        0
      ],
      "images": [
        "7",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "9": {
    "inputs": {
      "tile_size": 512,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "5",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "10": {
    "inputs": {
      "model_name": "4x-AnimeSharp.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "11": {
    "inputs": {
      "upscale_model": [
        "10",
        0
      ],
      "image": [
        "9",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "13": {
    "inputs": {
      "tile_size": 512,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "pixels": [
        "44",
        0
      ],
      "vae": [
        "1",
        2
      ]
    },
    "class_type": "VAEEncodeTiled",
    "_meta": {
      "title": "VAE Encode (Tiled)"
    }
  },
  "14": {
    "inputs": {
      "seed": [
        "43",
        0
      ],
      "steps": 20,
      "cfg": 4,
      "sampler_name": "euler",
      "scheduler": "normal",
      "denoise": 0.4,
      "model": [
        "18",
        0
      ],
      "positive": [
        "3",
        0
      ],
      "negative": [
        "4",
        0
      ],
      "latent_image": [
        "13",
        0
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "18": {
    "inputs": {
      "lora_name": "Realistic_Anime_-_Illustrious.safetensors",
      "strength_model": 0.4000000000000001,
      "strength_clip": 0.8000000000000002,
      "model": [
        "19",
        0
      ],
      "clip": [
        "19",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "19": {
    "inputs": {
      "lora_name": "FannyPacking_Illustrious_v2.safetensors",
      "strength_model": 0.7000000000000002,
      "strength_clip": 0.8,
      "model": [
        "1",
        0
      ],
      "clip": [
        "2",
        0
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "20": {
    "inputs": {
      "text": ""
    },
    "class_type": "Text _O",
    "_meta": {
      "title": "Prompt+"
    }
  },
  "21": {
    "inputs": {
      "string": [
        "37",
        0
      ]
    },
    "class_type": "String to Text",
    "_meta": {
      "title": "String to Text"
    }
  },
  "22": {
    "inputs": {
      "width": 960,
      "height": 640,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "23": {
    "inputs": {
      "width": [
        "45",
        1
      ],
      "height": [
        "45",
        0
      ],
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "24": {
    "inputs": {
      "text": [
        "20",
        0
      ],
      "sub_text": "portrait",
      "case_insensitive": true
    },
    "class_type": "Text Contains",
    "_meta": {
      "title": "Text Contains"
    }
  },
  "26": {
    "inputs": {
      "strings_to_remove": "  ",
      "match_case": false,
      "match_whole_string": false,
      "remove_extra_spaces": true,
      "input_string": [
        "20",
        0
      ]
    },
    "class_type": "StringStrip",
    "_meta": {
      "title": "String Strip"
    }
  },
  "27": {
    "inputs": {
      "ANY": [
        "26",
        0
      ],
      "IF_TRUE": [
        "20",
        0
      ],
      "IF_FALSE": [
        "34",
        0
      ]
    },
    "class_type": "If ANY return A else B-üî¨",
    "_meta": {
      "title": "If ANY return A else B"
    }
  },
  "31": {
    "inputs": {
      "string_a": [
        "33",
        0
      ],
      "string_b": [
        "32",
        0
      ]
    },
    "class_type": "ConcatStringSingle",
    "_meta": {
      "title": "Concat String (Single) üìÖüÖïüÖù"
    }
  },
  "32": {
    "inputs": {
      "truncate_by": "words",
      "truncate_from": "beginning",
      "truncate_to": 16,
      "text": [
        "27",
        0
      ]
    },
    "class_type": "Text String Truncate",
    "_meta": {
      "title": "Text String Truncate"
    }
  },
  "33": {
    "inputs": {
      "format": "%Y-%m-%d/%H%M%S - "
    },
    "class_type": "Date Time Format",
    "_meta": {
      "title": "Date Time Format"
    }
  },
  "34": {
    "inputs": {
      "seed": 466713925410352,
      "text": [
        "35",
        0
      ]
    },
    "class_type": "Text Random Line",
    "_meta": {
      "title": "Text Random Line"
    }
  },
  "35": {
    "inputs": {
      "text": "Anime girl with long auburn hair, emerald green eyes, playful smirk\nA tree\nLava flow spelling \"NOTEXT\""
    },
    "class_type": "Text _O",
    "_meta": {
      "title": "Promp List"
    }
  },
  "37": {
    "inputs": {
      "delimiter": ", ",
      "clean_whitespace": "true",
      "text_a": [
        "39",
        0
      ],
      "text_b": [
        "27",
        0
      ],
      "text_c": [
        "40",
        0
      ]
    },
    "class_type": "Text Concatenate",
    "_meta": {
      "title": "Text Concatenate"
    }
  },
  "39": {
    "inputs": {
      "String": "embedding:lazypos, illustriousanime, fannypacking"
    },
    "class_type": "String",
    "_meta": {
      "title": "Extra start String"
    }
  },
  "40": {
    "inputs": {
      "String": ""
    },
    "class_type": "String",
    "_meta": {
      "title": "Extra end String"
    }
  },
  "41": {
    "inputs": {
      "boolean_value": [
        "24",
        0
      ],
      "latent_false": [
        "22",
        0
      ],
      "latent_true": [
        "23",
        0
      ]
    },
    "class_type": "CR Latent Input Switch JK",
    "_meta": {
      "title": "Latent Input Switch JKüêâ"
    }
  },
  "43": {
    "inputs": {
      "seed": -1
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "44": {
    "inputs": {
      "upscale_method": "nearest-exact",
      "scale_by": 0.5000000000000001,
      "image": [
        "11",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "45": {
    "inputs": {
      "latent": [
        "22",
        0
      ]
    },
    "class_type": "Get Size JK",
    "_meta": {
      "title": "Get Size JKüêâ"
    }
  },
  "46": {
    "inputs": {
      "anything": [
        "7",
        0
      ]
    },
    "class_type": "easy clearCacheAll",
    "_meta": {
      "title": "Clear Cache All"
    }
  },
  "47": {
    "inputs": {
      "anything": [
        "7",
        0
      ]
    },
    "class_type": "easy cleanGpuUsed",
    "_meta": {
      "title": "Clean VRAM Used"
    }
  },
  "48": {
    "inputs": {
      "any_input": [
        "7",
        0
      ]
    },
    "class_type": "FluxAttentionCleanup",
    "_meta": {
      "title": "Flux Attention Cleanup"
    }
  }
}
